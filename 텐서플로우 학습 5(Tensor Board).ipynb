{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - 학습 5은 학습 4를 기반으로 진행합니다\n",
    "\n",
    "## Tensorboard : Graph Visualization 사용하기!! \n",
    "<br>\n",
    "\n",
    "**출처 ** <br>\n",
    "- https://www.youtube.com/watch?v=1yrBCTHbn8I\n",
    "- http://bcho.tistory.com/1159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = [[1,5,3,7,8,10,12],\n",
    "              [5,8,10,3,9,7,1]]\n",
    "label_data = [[0,0,0,1,0],\n",
    "              [1,0,0,0,0]]\n",
    "\n",
    "INPUT_SIZE = 7 \n",
    "HIDDEN_SIZE_1 = 10\n",
    "HIDDEN_SIZE_2 = 8\n",
    "CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [None, INPUT_SIZE], name=\"x\" )\n",
    "y = tf.placeholder(tf.float32, shape = [None, CLASSES], name=\"y\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_map = {x : input_data, y : label_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_hidden_1 = tf.Variable( tf.truncated_normal(shape=[INPUT_SIZE, HIDDEN_SIZE_1]) , dtype=tf.float32, name=\"weight_hidden_1\" ) \n",
    "bias_hidden_1 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_1]) , dtype=tf.float32, name = \"bias_hidden_1\" )\n",
    "\n",
    "weight_hidden_2 = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_1, HIDDEN_SIZE_2]) , dtype=tf.float32, name=\"weight_hidden_2\" ) \n",
    "bias_hidden_2 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_2]) , dtype=tf.float32, name = \"bias_hidden_2\" )\n",
    "\n",
    "weight_output = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_2, CLASSES]) , dtype=tf.float32, name=\"weight_output\" ) \n",
    "bias_output = tf.Variable( tf.zeros(shape=[CLASSES]) , dtype=tf.float32, name = \"bias_output\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_list = [weight_hidden_1, bias_hidden_1, weight_hidden_2, bias_hidden_2, weight_output, bias_output ]\n",
    "saver = tf.train.Saver(param_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각각의 scope 에 넣어준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('hidden_layer_1') as h1scope:\n",
    "    hidden_1 = tf.matmul( x , weight_hidden_1 , name=\"hidden_1\" ) + bias_hidden_1\n",
    "with tf.name_scope('hidden_layer_2') as h2scope:\n",
    "    hidden_2 = tf.matmul( hidden_1 , weight_hidden_2, name=\"hidden_2\" ) + bias_hidden_2\n",
    "with tf.name_scope('output_layer') as osscope:\n",
    "    answer = tf.matmul( hidden_2 , weight_output, name=\"answer\" ) + bias_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 일단 accuracy 는 무시하고 ./summaires 디렉토리에 생기는 파일을 주목해보자 !! (acc 가 이 코드는 자꾸 0 이 나온다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "step    : 0.000000\n",
      "loss    : nan\n",
      "accuracy: 0.000000\n",
      "---------------\n",
      "step    : 100.000000\n",
      "loss    : nan\n",
      "accuracy: 0.000000\n",
      "---------------\n",
      "step    : 200.000000\n",
      "loss    : nan\n",
      "accuracy: 0.000000\n",
      "---------------\n",
      "step    : 300.000000\n",
      "loss    : nan\n",
      "accuracy: 0.000000\n",
      "---------------\n",
      "step    : 400.000000\n",
      "loss    : nan\n",
      "accuracy: 0.000000\n",
      "---------------\n",
      "step    : 500.000000\n",
      "loss    : nan\n",
      "accuracy: 0.000000\n",
      "---------------\n",
      "step    : 600.000000\n",
      "loss    : nan\n",
      "accuracy: 0.000000\n",
      "---------------\n",
      "step    : 700.000000\n",
      "loss    : nan\n",
      "accuracy: 0.000000\n",
      "---------------\n",
      "step    : 800.000000\n",
      "loss    : nan\n",
      "accuracy: 0.000000\n",
      "---------------\n",
      "step    : 900.000000\n",
      "loss    : nan\n",
      "accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "Learning_Rate = 0.05\n",
    "\n",
    "cost_ = -y*tf.log(answer)-(1-y)*tf.log((1-answer))\n",
    "cost = tf.reduce_sum(cost_, reduction_indices=1)\n",
    "cost = tf.reduce_mean(cost, reduction_indices=0)\n",
    "train = tf.train.GradientDescentOptimizer(Learning_Rate).minimize(cost)\n",
    "\n",
    "comp_pred = tf.equal( tf.arg_max(answer, 1), tf.arg_max(y, 1) )\n",
    "accuracy = tf.reduce_mean(tf.cast(comp_pred, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "saver.restore(sess, './tensorflow_live.ckpt')\n",
    "merge = tf.summary.merge_all()\n",
    "\n",
    "for i in range(1000):\n",
    "    _ , loss, acc = sess.run([train, cost, accuracy], feed_dict = tensor_map)\n",
    "    if i%100 == 0:\n",
    "        train_writer = tf.summary.FileWriter('./summaries', sess.graph)\n",
    "        saver.save(sess, './tensorflow_live.ckpt')\n",
    "        print ( '---------------' ) \n",
    "        print ( 'step    : %f' %  i  )\n",
    "        print ( 'loss    : %f' % loss)\n",
    "        print ( 'accuracy: %f' % acc ) \n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "###  tensorboard --logdir=./\n",
    "summaries 폴더를 현재 디렉토리로 지정하고, 터미널에서 위의 명령어를 사용하여 텐서보드를 활성화시킨다.\n",
    "\n",
    "### 텐서 보드를 이용하여 보면 아래와 같은 구조를 가진다\n",
    "\n",
    "<img src=\"http://hellogohn.com/system/uploads/images/000/000/786/original/image.png?1522309702\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
