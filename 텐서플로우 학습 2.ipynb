{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow 모델 생성하기\n",
    "**출처 ** <br>\n",
    "- https://www.youtube.com/watch?v=NZz2yq0G5LU\n",
    "- http://bcho.tistory.com/1154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input과 label 데이터 설정\n",
    "** 먼저 간단한 모델을 살펴보자 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = [[1,5,3,7,8,10,12],\n",
    "              [5,8,10,3,9,7,1]]\n",
    "label_data = [[0,0,0,1,0],\n",
    "              [1,0,0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 7 \n",
    "HIDDEN_SIZE_1 = 10\n",
    "HIDDEN_SIZE_2 = 8\n",
    "CLASSES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** shape 에서 첫 번째 요소는 batch의 크기. 일반적으로 잘 모르기 때문에 None으로 써도 된다. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [None, INPUT_SIZE] )\n",
    "y = tf.placeholder(tf.float32, shape = [None, CLASSES] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_map = {x : input_data, y : label_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** input weight 정의 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_hidden_1 = tf.Variable( tf.truncated_normal(shape=[INPUT_SIZE, HIDDEN_SIZE_1]) , dtype=tf.float32 ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** bias 정의 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_hidden_1 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_1]) , dtype=tf.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul( x , weight_hidden_1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 7), dtype=float32)\n",
      "Tensor(\"Variable/read:0\", shape=(7, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (x)\n",
    "print (weight_hidden_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_1 = tf.matmul( x , weight_hidden_1 ) + bias_hidden_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_hidden_2 = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_1, HIDDEN_SIZE_2]) , dtype=tf.float32 ) \n",
    "bias_hidden_2 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_2]) , dtype=tf.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_2 = tf.matmul( hidden_1 , weight_hidden_2 ) + bias_hidden_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_output = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_2, CLASSES]) , dtype=tf.float32 ) \n",
    "bias_output = tf.Variable( tf.zeros(shape=[CLASSES]) , dtype=tf.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer = tf.matmul( hidden_2 , weight_output ) + bias_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 위의 내용을 한 번에 모아서 해보자 ** \n",
    "\n",
    "신경망을 미리 설계해 놓고 아래에서 연산을 수행하여 답을 도출해낸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_hidden_1 = tf.Variable( tf.truncated_normal(shape=[INPUT_SIZE, HIDDEN_SIZE_1]) , dtype=tf.float32 ) \n",
    "bias_hidden_1 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_1]) , dtype=tf.float32 )\n",
    "\n",
    "weight_hidden_2 = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_1, HIDDEN_SIZE_2]) , dtype=tf.float32 ) \n",
    "bias_hidden_2 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_2]) , dtype=tf.float32 )\n",
    "\n",
    "weight_output = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_2, CLASSES]) , dtype=tf.float32 ) \n",
    "bias_output = tf.Variable( tf.zeros(shape=[CLASSES]) , dtype=tf.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_1 = tf.matmul( x , weight_hidden_1 ) + bias_hidden_1\n",
    "hidden_2 = tf.matmul( hidden_1 , weight_hidden_2 ) + bias_hidden_2\n",
    "answer = tf.matmul( hidden_2 , weight_output ) + bias_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구조\n",
    "    Input -  ㅁ  - ㅁ  - ㅁ - ㅁ   - ㅁ - ㅁ  - answer\n",
    "             |     |    |    |     |    |\n",
    "             w1   b2    w2   b2    wo   bo\n",
    "             \n",
    "    \n",
    "    인풋   히든1  2  결과  \n",
    "\n",
    "    7     10    8   5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 7), dtype=float32)\n",
      "Tensor(\"add_3:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"add_4:0\", shape=(?, 8), dtype=float32)\n",
      "Tensor(\"add_5:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (x)\n",
    "print (hidden_1)\n",
    "print (hidden_2)\n",
    "print (answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Variable_6/read:0\", shape=(7, 10), dtype=float32)\n",
      "Tensor(\"Variable_7/read:0\", shape=(10,), dtype=float32)\n",
      "Tensor(\"Variable_8/read:0\", shape=(10, 8), dtype=float32)\n",
      "Tensor(\"Variable_9/read:0\", shape=(8,), dtype=float32)\n",
      "Tensor(\"Variable_10/read:0\", shape=(8, 5), dtype=float32)\n",
      "Tensor(\"Variable_11/read:0\", shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (weight_hidden_1)\n",
    "print (bias_hidden_1)\n",
    "\n",
    "print (weight_hidden_2)\n",
    "print (bias_hidden_2)\n",
    "\n",
    "print (weight_output)\n",
    "print (bias_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** sigmoid  함수 적용 법 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_hidden_1 = tf.Variable( tf.truncated_normal(shape=[INPUT_SIZE, HIDDEN_SIZE_1]) , dtype=tf.float32 ) \n",
    "bias_hidden_1 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_1]) , dtype=tf.float32 )\n",
    "hidden_1 = tf.sigmoid(tf.matmul( x , weight_hidden_1 ) + bias_hidden_1)\n",
    "\n",
    "weight_hidden_2 = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_1, HIDDEN_SIZE_2]) , dtype=tf.float32 ) \n",
    "bias_hidden_2 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_2]) , dtype=tf.float32 )\n",
    "hidden_2 = tf.sigmoid(tf.matmul( hidden_1 , weight_hidden_2 ) + bias_hidden_2)\n",
    "\n",
    "weight_output = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_2, CLASSES]) , dtype=tf.float32 ) \n",
    "bias_output = tf.Variable( tf.zeros(shape=[CLASSES]) , dtype=tf.float32 )\n",
    "\n",
    "answer = tf.sigmoid(tf.matmul( hidden_2 , weight_output ) + bias_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** cost 엔트로피 ** ( tip : 매뉴얼을 항상 자주 보자 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = -answer*tf.log(answer)-(1-answer)*tf.log((1-answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30356076,  0.69175231,  0.55692714,  0.66432106,  0.56890756],\n",
       "       [ 0.22203758,  0.65581667,  0.42899519,  0.63220489,  0.61964118]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "sess.run(cost, feed_dict = tensor_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** recude sum 과 reduce mean 사용해보기 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.089397"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_sum(-answer*tf.log(answer)-(1-answer)*tf.log((1-answer)))\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "sess.run(cost, feed_dict = tensor_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58518952"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_mean(-answer*tf.log(answer)-(1-answer)*tf.log((1-answer)))\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "sess.run(cost, feed_dict = tensor_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 수행 ** \n",
    "- cost를 최소화 하는 방향으로 최적화 해야 되니까 gradient descent가 필요.\n",
    "- learning rate 사용\n",
    "\n",
    "\n",
    "\n",
    "#### 조대협님의 블로그에서 가져온 내용 (Mnist data를 기준으로 한다. 자세한 내용은 링크 참조)\n",
    "\n",
    "우리가 구하고자 하는 값은 x 값으로 학습을 시켜서 0~9를 가장 잘 구별해내는 W와 b의 값을 찾는 일이다. \n",
    "\n",
    "여기서 코드를 주의깊게 봤다면 하나의 의문이 생길것이다.\n",
    "\n",
    "x의 데이타는 총 55000개로, 55000x784 행렬이 되고, W는 784x10 행렬이다. 이 둘을 곱하면, 55000x10 행렬이 되는데, b는 1x10 행렬로 차원이 달라서 합이 되지 않는다. \n",
    "\n",
    "텐서플로우와 파이썬에서는 이렇게 차원이 다른 행렬을 큰 행렬의 크기로 늘려주는 기능이 있는데, 이를 브로드 캐스팅이라고 한다. (브로드 캐스팅 개념 참고 - http://bcho.tistory.com/1153)\n",
    "\n",
    "브로드 캐스팅에 의해서 b는 55000x10 사이즈로 자동으로 늘어나고 각 행에는 첫행과 같은 데이타들로 채워지게 된다. \n",
    "\n",
    "소프트맥스 알고리즘을 이해하고 사용해도 좋지만, 텐서플로우에는 이미 tf.nn.softmax 라는 함수로 만들어져 있고, 대부분 많이 알려진 머신러닝 모델들은 샘플들이 많이 있기 때문에, 대략적인 원리만 이해하고 가져다 쓰는 것을 권장한다.\n",
    "\n",
    "보통 모델을 다 이해하려고 하다가 수학에서 부딪혀서 포기하는 경우가 많은데, 디테일한 모델을 이해하기 힘들면, 그냥 함수나 예제코드를 가져다 쓰는 방법으로 접근하자. \n",
    "\n",
    "우리가 일반적인 프로그래밍에서도 해쉬테이블이나 트리와 같은 자료구조에 대해서 대략적인 개념만 이해하고 미리 정의된 라이브러리를 사용하지 직접 해쉬 테이블등을 구현하는 경우는 드물다.\n",
    "\n",
    "\n",
    "### 코스트(비용) 함수\n",
    "\n",
    "이 소프트맥스 함수에 대한 코스트 함수는 크로스엔트로피 (Cross entropy) 함수의 평균을 이용하는데, 복잡한 산식 없이 그냥 외워서 쓰자. \n",
    "다행이도 크로스엔트로피 함수역시 함수로 구현이 되어있다.\n",
    "\n",
    "** Cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(tf.matmul(x, W) + b, y_)) ** \n",
    "\n",
    "가설에 의해 계산된 값 y를 넣지 않고 tf.matmul(x, W) + b 를 넣은 이유는  tf.nn.softmax_cross_entropy_with_logits 함수 자체가 softmax를 포함하기 때문이다. y_은 학습을 위해서 입력된 값이다.  \n",
    "\n",
    "\n",
    "-> 코스트 함수로 위 함수는 써 본 적은 없고, 자세한 내용은 저도 잘 모르겠으나 일단 사용해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0.52609128]\n",
      "Step :  0\n",
      "[None, 0.52000934]\n",
      "Step :  1\n",
      "[None, 0.51365632]\n",
      "Step :  2\n",
      "[None, 0.50724244]\n",
      "Step :  3\n",
      "[None, 0.5009836]\n",
      "Step :  4\n",
      "[None, 0.49504423]\n",
      "Step :  5\n",
      "[None, 0.48950952]\n",
      "Step :  6\n",
      "[None, 0.48439676]\n",
      "Step :  7\n",
      "[None, 0.47968206]\n",
      "Step :  8\n",
      "[None, 0.47532463]\n",
      "Step :  9\n"
     ]
    }
   ],
   "source": [
    "Learning_Rate = 0.05\n",
    "\n",
    "cost = tf.reduce_mean(-answer*tf.log(answer)-(1-answer)*tf.log((1-answer)))\n",
    "train = tf.train.GradientDescentOptimizer(Learning_Rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(10):\n",
    "    print (sess.run([train, cost], feed_dict = tensor_map))\n",
    "    print (\"Step : \",i )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 학습 100 번 수행 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0.47128057]\n",
      "Step :  0\n",
      "[None, 0.46750903]\n",
      "Step :  1\n",
      "[None, 0.46397358]\n",
      "Step :  2\n",
      "[None, 0.46064264]\n",
      "Step :  3\n",
      "[None, 0.45748872]\n",
      "Step :  4\n",
      "[None, 0.45448819]\n",
      "Step :  5\n",
      "[None, 0.45162073]\n",
      "Step :  6\n",
      "[None, 0.44886857]\n",
      "Step :  7\n",
      "[None, 0.44621673]\n",
      "Step :  8\n",
      "[None, 0.44365215]\n",
      "Step :  9\n",
      "[None, 0.44116384]\n",
      "Step :  10\n",
      "[None, 0.43874207]\n",
      "Step :  11\n",
      "[None, 0.43637878]\n",
      "Step :  12\n",
      "[None, 0.43406677]\n",
      "Step :  13\n",
      "[None, 0.43180007]\n",
      "Step :  14\n",
      "[None, 0.42957336]\n",
      "Step :  15\n",
      "[None, 0.42738199]\n",
      "Step :  16\n",
      "[None, 0.42522201]\n",
      "Step :  17\n",
      "[None, 0.42309007]\n",
      "Step :  18\n",
      "[None, 0.42098293]\n",
      "Step :  19\n",
      "[None, 0.41889802]\n",
      "Step :  20\n",
      "[None, 0.41683301]\n",
      "Step :  21\n",
      "[None, 0.41478586]\n",
      "Step :  22\n",
      "[None, 0.41275483]\n",
      "Step :  23\n",
      "[None, 0.41073829]\n",
      "Step :  24\n",
      "[None, 0.4087348]\n",
      "Step :  25\n",
      "[None, 0.4067432]\n",
      "Step :  26\n",
      "[None, 0.40476245]\n",
      "Step :  27\n",
      "[None, 0.4027915]\n",
      "Step :  28\n",
      "[None, 0.40082961]\n",
      "Step :  29\n",
      "[None, 0.39887592]\n",
      "Step :  30\n",
      "[None, 0.39692989]\n",
      "Step :  31\n",
      "[None, 0.39499098]\n",
      "Step :  32\n",
      "[None, 0.3930586]\n",
      "Step :  33\n",
      "[None, 0.39113238]\n",
      "Step :  34\n",
      "[None, 0.38921189]\n",
      "Step :  35\n",
      "[None, 0.38729686]\n",
      "Step :  36\n",
      "[None, 0.38538703]\n",
      "Step :  37\n",
      "[None, 0.38348204]\n",
      "Step :  38\n",
      "[None, 0.38158178]\n",
      "Step :  39\n",
      "[None, 0.37968603]\n",
      "Step :  40\n",
      "[None, 0.37779465]\n",
      "Step :  41\n",
      "[None, 0.37590757]\n",
      "Step :  42\n",
      "[None, 0.37402463]\n",
      "Step :  43\n",
      "[None, 0.37214571]\n",
      "Step :  44\n",
      "[None, 0.37027088]\n",
      "Step :  45\n",
      "[None, 0.36839995]\n",
      "Step :  46\n",
      "[None, 0.36653298]\n",
      "Step :  47\n",
      "[None, 0.36466995]\n",
      "Step :  48\n",
      "[None, 0.36281079]\n",
      "Step :  49\n",
      "[None, 0.36095554]\n",
      "Step :  50\n",
      "[None, 0.35910416]\n",
      "Step :  51\n",
      "[None, 0.3572568]\n",
      "Step :  52\n",
      "[None, 0.35541341]\n",
      "Step :  53\n",
      "[None, 0.35357398]\n",
      "Step :  54\n",
      "[None, 0.3517386]\n",
      "Step :  55\n",
      "[None, 0.34990734]\n",
      "Step :  56\n",
      "[None, 0.34808016]\n",
      "Step :  57\n",
      "[None, 0.34625715]\n",
      "Step :  58\n",
      "[None, 0.3444384]\n",
      "Step :  59\n",
      "[None, 0.34262389]\n",
      "Step :  60\n",
      "[None, 0.34081379]\n",
      "Step :  61\n",
      "[None, 0.33900803]\n",
      "Step :  62\n",
      "[None, 0.33720681]\n",
      "Step :  63\n",
      "[None, 0.33541012]\n",
      "Step :  64\n",
      "[None, 0.33361799]\n",
      "Step :  65\n",
      "[None, 0.33183047]\n",
      "Step :  66\n",
      "[None, 0.3300477]\n",
      "Step :  67\n",
      "[None, 0.32826966]\n",
      "Step :  68\n",
      "[None, 0.32649654]\n",
      "Step :  69\n",
      "[None, 0.32472831]\n",
      "Step :  70\n",
      "[None, 0.32296506]\n",
      "Step :  71\n",
      "[None, 0.32120675]\n",
      "Step :  72\n",
      "[None, 0.31945363]\n",
      "Step :  73\n",
      "[None, 0.31770557]\n",
      "Step :  74\n",
      "[None, 0.31596273]\n",
      "Step :  75\n",
      "[None, 0.3142252]\n",
      "Step :  76\n",
      "[None, 0.31249294]\n",
      "Step :  77\n",
      "[None, 0.31076604]\n",
      "Step :  78\n",
      "[None, 0.30904457]\n",
      "Step :  79\n",
      "[None, 0.30732864]\n",
      "Step :  80\n",
      "[None, 0.30561811]\n",
      "Step :  81\n",
      "[None, 0.30391321]\n",
      "Step :  82\n",
      "[None, 0.30221388]\n",
      "Step :  83\n",
      "[None, 0.30052024]\n",
      "Step :  84\n",
      "[None, 0.29883218]\n",
      "Step :  85\n",
      "[None, 0.29714993]\n",
      "Step :  86\n",
      "[None, 0.2954734]\n",
      "Step :  87\n",
      "[None, 0.29380268]\n",
      "Step :  88\n",
      "[None, 0.29213774]\n",
      "Step :  89\n",
      "[None, 0.29047865]\n",
      "Step :  90\n",
      "[None, 0.28882539]\n",
      "Step :  91\n",
      "[None, 0.28717804]\n",
      "Step :  92\n",
      "[None, 0.28553659]\n",
      "Step :  93\n",
      "[None, 0.28390101]\n",
      "Step :  94\n",
      "[None, 0.28227133]\n",
      "Step :  95\n",
      "[None, 0.28064758]\n",
      "Step :  96\n",
      "[None, 0.27902967]\n",
      "Step :  97\n",
      "[None, 0.27741775]\n",
      "Step :  98\n",
      "[None, 0.27581167]\n",
      "Step :  99\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print (sess.run([train, cost], feed_dict = tensor_map))\n",
    "    print (\"Step : \",i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
