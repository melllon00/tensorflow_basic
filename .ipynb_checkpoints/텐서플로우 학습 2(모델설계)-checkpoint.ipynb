{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow 모델 생성하기\n",
    "**출처 ** <br>\n",
    "- https://www.youtube.com/watch?v=NZz2yq0G5LU\n",
    "- http://bcho.tistory.com/1154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input과 label 데이터 설정\n",
    "** 먼저 간단한 모델을 살펴보자 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = [[1,5,3,7,8,10,12],\n",
    "              [5,8,10,3,9,7,1]]\n",
    "label_data = [[0,0,0,1,0],\n",
    "              [1,0,0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 7 \n",
    "HIDDEN_SIZE_1 = 10\n",
    "HIDDEN_SIZE_2 = 8\n",
    "CLASSES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** shape 에서 첫 번째 요소는 batch의 크기. 일반적으로 잘 모르기 때문에 None으로 써도 된다. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [None, INPUT_SIZE] )\n",
    "y = tf.placeholder(tf.float32, shape = [None, CLASSES] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_map = {x : input_data, y : label_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** input weight 정의 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_hidden_1 = tf.Variable( tf.truncated_normal(shape=[INPUT_SIZE, HIDDEN_SIZE_1]) , dtype=tf.float32 ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** bias 정의 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_hidden_1 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_1]) , dtype=tf.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul( x , weight_hidden_1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 7), dtype=float32)\n",
      "Tensor(\"Variable/read:0\", shape=(7, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (x)\n",
    "print (weight_hidden_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_1 = tf.matmul( x , weight_hidden_1 ) + bias_hidden_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_hidden_2 = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_1, HIDDEN_SIZE_2]) , dtype=tf.float32 ) \n",
    "bias_hidden_2 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_2]) , dtype=tf.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_2 = tf.matmul( hidden_1 , weight_hidden_2 ) + bias_hidden_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_output = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_2, CLASSES]) , dtype=tf.float32 ) \n",
    "bias_output = tf.Variable( tf.zeros(shape=[CLASSES]) , dtype=tf.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer = tf.matmul( hidden_2 , weight_output ) + bias_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 위의 내용을 한 번에 모아서 해보자 ** \n",
    "\n",
    "신경망을 미리 설계해 놓고 아래에서 연산을 수행하여 답을 도출해낸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_hidden_1 = tf.Variable( tf.truncated_normal(shape=[INPUT_SIZE, HIDDEN_SIZE_1]) , dtype=tf.float32 ) \n",
    "bias_hidden_1 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_1]) , dtype=tf.float32 )\n",
    "\n",
    "weight_hidden_2 = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_1, HIDDEN_SIZE_2]) , dtype=tf.float32 ) \n",
    "bias_hidden_2 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_2]) , dtype=tf.float32 )\n",
    "\n",
    "weight_output = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_2, CLASSES]) , dtype=tf.float32 ) \n",
    "bias_output = tf.Variable( tf.zeros(shape=[CLASSES]) , dtype=tf.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_1 = tf.matmul( x , weight_hidden_1 ) + bias_hidden_1\n",
    "hidden_2 = tf.matmul( hidden_1 , weight_hidden_2 ) + bias_hidden_2\n",
    "answer = tf.matmul( hidden_2 , weight_output ) + bias_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구조\n",
    "    Input -  ㅁ  - ㅁ  - ㅁ - ㅁ   - ㅁ - ㅁ  - answer\n",
    "             |     |    |    |     |    |\n",
    "             w1   b2    w2   b2    wo   bo\n",
    "             \n",
    "    \n",
    "    인풋   히든1  2  결과  \n",
    "\n",
    "    7     10    8   5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 7), dtype=float32)\n",
      "Tensor(\"add_3:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"add_4:0\", shape=(?, 8), dtype=float32)\n",
      "Tensor(\"add_5:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (x)\n",
    "print (hidden_1)\n",
    "print (hidden_2)\n",
    "print (answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Variable_6/read:0\", shape=(7, 10), dtype=float32)\n",
      "Tensor(\"Variable_7/read:0\", shape=(10,), dtype=float32)\n",
      "Tensor(\"Variable_8/read:0\", shape=(10, 8), dtype=float32)\n",
      "Tensor(\"Variable_9/read:0\", shape=(8,), dtype=float32)\n",
      "Tensor(\"Variable_10/read:0\", shape=(8, 5), dtype=float32)\n",
      "Tensor(\"Variable_11/read:0\", shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (weight_hidden_1)\n",
    "print (bias_hidden_1)\n",
    "\n",
    "print (weight_hidden_2)\n",
    "print (bias_hidden_2)\n",
    "\n",
    "print (weight_output)\n",
    "print (bias_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** sigmoid  함수 적용 법 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_hidden_1 = tf.Variable( tf.truncated_normal(shape=[INPUT_SIZE, HIDDEN_SIZE_1]) , dtype=tf.float32 ) \n",
    "bias_hidden_1 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_1]) , dtype=tf.float32 )\n",
    "hidden_1 = tf.sigmoid(tf.matmul( x , weight_hidden_1 ) + bias_hidden_1)\n",
    "\n",
    "weight_hidden_2 = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_1, HIDDEN_SIZE_2]) , dtype=tf.float32 ) \n",
    "bias_hidden_2 = tf.Variable( tf.zeros(shape=[HIDDEN_SIZE_2]) , dtype=tf.float32 )\n",
    "hidden_2 = tf.sigmoid(tf.matmul( hidden_1 , weight_hidden_2 ) + bias_hidden_2)\n",
    "\n",
    "weight_output = tf.Variable( tf.truncated_normal(shape=[HIDDEN_SIZE_2, CLASSES]) , dtype=tf.float32 ) \n",
    "bias_output = tf.Variable( tf.zeros(shape=[CLASSES]) , dtype=tf.float32 )\n",
    "\n",
    "answer = tf.sigmoid(tf.matmul( hidden_2 , weight_output ) + bias_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** cost 엔트로피 ** ( tip : 매뉴얼을 항상 자주 보자 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = -y*tf.log(answer)-(1-y)*tf.log((1-answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.33245099,  0.17650527,  3.64532757,  0.4300445 ,  0.0531444 ],\n",
       "       [ 0.48834652,  0.2071031 ,  3.64621139,  0.91910106,  0.06918658]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "sess.run(cost, feed_dict = tensor_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** recude sum 과 reduce mean 사용해보기 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.1844816"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_sum(-y*tf.log(answer)-(1-y)*tf.log((1-answer)))\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "sess.run(cost, feed_dict = tensor_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98683512"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_mean(-y*tf.log(answer)-(1-y)*tf.log((1-answer)))\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "sess.run(cost, feed_dict = tensor_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 수행 ** \n",
    "- cost를 최소화 하는 방향으로 최적화 해야 되니까 gradient descent가 필요.\n",
    "- learning rate 사용\n",
    "\n",
    "\n",
    "\n",
    "#### 조대협님의 블로그에서 가져온 내용 (Mnist data를 기준으로 한다. 자세한 내용은 링크 참조)\n",
    "\n",
    "우리가 구하고자 하는 값은 x 값으로 학습을 시켜서 0~9를 가장 잘 구별해내는 W와 b의 값을 찾는 일이다. \n",
    "\n",
    "여기서 코드를 주의깊게 봤다면 하나의 의문이 생길것이다.\n",
    "\n",
    "x의 데이타는 총 55000개로, 55000x784 행렬이 되고, W는 784x10 행렬이다. 이 둘을 곱하면, 55000x10 행렬이 되는데, b는 1x10 행렬로 차원이 달라서 합이 되지 않는다. \n",
    "\n",
    "텐서플로우와 파이썬에서는 이렇게 차원이 다른 행렬을 큰 행렬의 크기로 늘려주는 기능이 있는데, 이를 브로드 캐스팅이라고 한다. (브로드 캐스팅 개념 참고 - http://bcho.tistory.com/1153)\n",
    "\n",
    "브로드 캐스팅에 의해서 b는 55000x10 사이즈로 자동으로 늘어나고 각 행에는 첫행과 같은 데이타들로 채워지게 된다. \n",
    "\n",
    "소프트맥스 알고리즘을 이해하고 사용해도 좋지만, 텐서플로우에는 이미 tf.nn.softmax 라는 함수로 만들어져 있고, 대부분 많이 알려진 머신러닝 모델들은 샘플들이 많이 있기 때문에, 대략적인 원리만 이해하고 가져다 쓰는 것을 권장한다.\n",
    "\n",
    "보통 모델을 다 이해하려고 하다가 수학에서 부딪혀서 포기하는 경우가 많은데, 디테일한 모델을 이해하기 힘들면, 그냥 함수나 예제코드를 가져다 쓰는 방법으로 접근하자. \n",
    "\n",
    "우리가 일반적인 프로그래밍에서도 해쉬테이블이나 트리와 같은 자료구조에 대해서 대략적인 개념만 이해하고 미리 정의된 라이브러리를 사용하지 직접 해쉬 테이블등을 구현하는 경우는 드물다.\n",
    "\n",
    "\n",
    "### 코스트(비용) 함수\n",
    "\n",
    "이 소프트맥스 함수에 대한 코스트 함수는 크로스엔트로피 (Cross entropy) 함수의 평균을 이용하는데, 복잡한 산식 없이 그냥 외워서 쓰자. \n",
    "다행이도 크로스엔트로피 함수역시 함수로 구현이 되어있다.\n",
    "\n",
    "** Cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(tf.matmul(x, W) + b, y_)) ** \n",
    "\n",
    "가설에 의해 계산된 값 y를 넣지 않고 tf.matmul(x, W) + b 를 넣은 이유는  tf.nn.softmax_cross_entropy_with_logits 함수 자체가 softmax를 포함하기 때문이다. y_은 학습을 위해서 입력된 값이다.  \n",
    "\n",
    "\n",
    "-> 코스트 함수로 위 함수는 써 본 적은 없고, 자세한 내용은 저도 잘 모르겠으나 일단 사용해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 1.005991]\n",
      "Step :  0\n",
      "[None, 0.9897567]\n",
      "Step :  1\n",
      "[None, 0.97342128]\n",
      "Step :  2\n",
      "[None, 0.95689833]\n",
      "Step :  3\n",
      "[None, 0.94007456]\n",
      "Step :  4\n",
      "[None, 0.92279834]\n",
      "Step :  5\n",
      "[None, 0.90486622]\n",
      "Step :  6\n",
      "[None, 0.88602316]\n",
      "Step :  7\n",
      "[None, 0.86601162]\n",
      "Step :  8\n",
      "[None, 0.84476393]\n",
      "Step :  9\n"
     ]
    }
   ],
   "source": [
    "Learning_Rate = 0.05\n",
    "\n",
    "cost = tf.reduce_mean(-y*tf.log(answer)-(1-y)*tf.log((1-answer)))\n",
    "train = tf.train.GradientDescentOptimizer(Learning_Rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(10):\n",
    "    print (sess.run([train, cost], feed_dict = tensor_map))\n",
    "    print (\"Step : \",i )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 학습 100 번 수행 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0.82282323]\n",
      "Step :  0\n",
      "[None, 0.80167067]\n",
      "Step :  1\n",
      "[None, 0.78300524]\n",
      "Step :  2\n",
      "[None, 0.76736492]\n",
      "Step :  3\n",
      "[None, 0.75414431]\n",
      "Step :  4\n",
      "[None, 0.74253953]\n",
      "Step :  5\n",
      "[None, 0.73197526]\n",
      "Step :  6\n",
      "[None, 0.72209966]\n",
      "Step :  7\n",
      "[None, 0.7127009]\n",
      "Step :  8\n",
      "[None, 0.70364749]\n",
      "Step :  9\n",
      "[None, 0.69485533]\n",
      "Step :  10\n",
      "[None, 0.68626755]\n",
      "Step :  11\n",
      "[None, 0.67784488]\n",
      "Step :  12\n",
      "[None, 0.66955864]\n",
      "Step :  13\n",
      "[None, 0.66138804]\n",
      "Step :  14\n",
      "[None, 0.65331715]\n",
      "Step :  15\n",
      "[None, 0.64533377]\n",
      "Step :  16\n",
      "[None, 0.63742936]\n",
      "Step :  17\n",
      "[None, 0.62959808]\n",
      "Step :  18\n",
      "[None, 0.62183756]\n",
      "Step :  19\n",
      "[None, 0.6141488]\n",
      "Step :  20\n",
      "[None, 0.60653651]\n",
      "Step :  21\n",
      "[None, 0.5990088]\n",
      "Step :  22\n",
      "[None, 0.59157741]\n",
      "Step :  23\n",
      "[None, 0.58425629]\n",
      "Step :  24\n",
      "[None, 0.5770601]\n",
      "Step :  25\n",
      "[None, 0.57000315]\n",
      "Step :  26\n",
      "[None, 0.56309664]\n",
      "Step :  27\n",
      "[None, 0.55634892]\n",
      "Step :  28\n",
      "[None, 0.54976398]\n",
      "Step :  29\n",
      "[None, 0.54334205]\n",
      "Step :  30\n",
      "[None, 0.53708076]\n",
      "Step :  31\n",
      "[None, 0.5309751]\n",
      "Step :  32\n",
      "[None, 0.52501887]\n",
      "Step :  33\n",
      "[None, 0.51920545]\n",
      "Step :  34\n",
      "[None, 0.51352805]\n",
      "Step :  35\n",
      "[None, 0.50798011]\n",
      "Step :  36\n",
      "[None, 0.50255555]\n",
      "Step :  37\n",
      "[None, 0.49724874]\n",
      "Step :  38\n",
      "[None, 0.49205464]\n",
      "Step :  39\n",
      "[None, 0.48696867]\n",
      "Step :  40\n",
      "[None, 0.48198685]\n",
      "Step :  41\n",
      "[None, 0.47710523]\n",
      "Step :  42\n",
      "[None, 0.47232071]\n",
      "Step :  43\n",
      "[None, 0.46763015]\n",
      "Step :  44\n",
      "[None, 0.46303076]\n",
      "Step :  45\n",
      "[None, 0.45852]\n",
      "Step :  46\n",
      "[None, 0.45409536]\n",
      "Step :  47\n",
      "[None, 0.44975466]\n",
      "Step :  48\n",
      "[None, 0.4454959]\n",
      "Step :  49\n",
      "[None, 0.44131678]\n",
      "Step :  50\n",
      "[None, 0.43721586]\n",
      "Step :  51\n",
      "[None, 0.43319097]\n",
      "Step :  52\n",
      "[None, 0.42924052]\n",
      "Step :  53\n",
      "[None, 0.42536283]\n",
      "Step :  54\n",
      "[None, 0.42155623]\n",
      "Step :  55\n",
      "[None, 0.41781917]\n",
      "Step :  56\n",
      "[None, 0.41415018]\n",
      "Step :  57\n",
      "[None, 0.41054779]\n",
      "Step :  58\n",
      "[None, 0.40701047]\n",
      "Step :  59\n",
      "[None, 0.40353695]\n",
      "Step :  60\n",
      "[None, 0.40012574]\n",
      "Step :  61\n",
      "[None, 0.3967756]\n",
      "Step :  62\n",
      "[None, 0.39348522]\n",
      "Step :  63\n",
      "[None, 0.39025325]\n",
      "Step :  64\n",
      "[None, 0.38707849]\n",
      "Step :  65\n",
      "[None, 0.38395974]\n",
      "Step :  66\n",
      "[None, 0.38089576]\n",
      "Step :  67\n",
      "[None, 0.37788543]\n",
      "Step :  68\n",
      "[None, 0.37492755]\n",
      "Step :  69\n",
      "[None, 0.37202102]\n",
      "Step :  70\n",
      "[None, 0.36916474]\n",
      "Step :  71\n",
      "[None, 0.36635768]\n",
      "Step :  72\n",
      "[None, 0.36359864]\n",
      "Step :  73\n",
      "[None, 0.36088678]\n",
      "Step :  74\n",
      "[None, 0.35822096]\n",
      "Step :  75\n",
      "[None, 0.35560024]\n",
      "Step :  76\n",
      "[None, 0.35302359]\n",
      "Step :  77\n",
      "[None, 0.35049018]\n",
      "Step :  78\n",
      "[None, 0.34799904]\n",
      "Step :  79\n",
      "[None, 0.34554917]\n",
      "Step :  80\n",
      "[None, 0.3431398]\n",
      "Step :  81\n",
      "[None, 0.34076998]\n",
      "Step :  82\n",
      "[None, 0.33843893]\n",
      "Step :  83\n",
      "[None, 0.3361457]\n",
      "Step :  84\n",
      "[None, 0.3338896]\n",
      "Step :  85\n",
      "[None, 0.33166984]\n",
      "Step :  86\n",
      "[None, 0.3294856]\n",
      "Step :  87\n",
      "[None, 0.32733601]\n",
      "Step :  88\n",
      "[None, 0.3252205]\n",
      "Step :  89\n",
      "[None, 0.32313833]\n",
      "Step :  90\n",
      "[None, 0.3210887]\n",
      "Step :  91\n",
      "[None, 0.31907099]\n",
      "Step :  92\n",
      "[None, 0.31708446]\n",
      "Step :  93\n",
      "[None, 0.31512851]\n",
      "Step :  94\n",
      "[None, 0.31320247]\n",
      "Step :  95\n",
      "[None, 0.3113057]\n",
      "Step :  96\n",
      "[None, 0.3094376]\n",
      "Step :  97\n",
      "[None, 0.30759758]\n",
      "Step :  98\n",
      "[None, 0.305785]\n",
      "Step :  99\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print (sess.run([train, cost], feed_dict = tensor_map))\n",
    "    print (\"Step : \",i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
